# -*- coding: utf-8 -*-
"""Untitled22.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aLW3PsLOBK2TCBurMgtq3zx15x52Ltht
"""

import os
import urllib.request
import numpy as np
import cv2
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model
from sklearn.metrics import mean_squared_error
import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import webbrowser

# 모델 로딩
model_path = "robotarm_model.h5"
if not os.path.exists(model_path):
    raise FileNotFoundError(f"❌ 모델 파일({model_path})이 존재하지 않습니다.")
model = load_model(model_path, compile=False)

# 로봇 정보
robot_models = {
    "UR3e": {
        "gt": np.array([151.8, 243.5, 213.2, 131.5, 85.3, 92.1], dtype=np.float32),
        "videos": [f"UR3e_{i}.mp4" for i in range(1, 11)]
    },
    "UR5e": {
        "gt": np.array([162.5, 425.0, 392.2, 133.3, 99.7, 99.6], dtype=np.float32),
        "videos": [f"UR5e_{i}.mp4" for i in range(1, 11)]
    },
    "UR10e": {
        "gt": np.array([180.7, 612.7, 571.5, 174.1, 119.8, 116.5], dtype=np.float32),
        "videos": [f"UR10e_{i}.mp4" for i in range(1, 11)]
    }
}
base_url = "https://raw.githubusercontent.com/x-ohyeong/robotarm_project/main/"
os.makedirs("downloads", exist_ok=True)

# 프레임 추출
def extract_frames(video_path, out_dir, max_frames=100):
    os.makedirs(out_dir, exist_ok=True)
    cap = cv2.VideoCapture(video_path)
    idx = 0
    while idx < max_frames:
        ret, frame = cap.read()
        if not ret:
            break
        frame = cv2.resize(frame, (128, 128)).astype(np.float32) / 255.0
        np.save(f"{out_dir}/frame_{idx:04d}.npy", frame)
        idx += 1
    cap.release()
    return [f"{out_dir}/frame_{i:04d}.npy" for i in range(idx)]

def extract_middle_frame(video_path):
    cap = cv2.VideoCapture(video_path)
    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    middle = total // 2
    cap.set(cv2.CAP_PROP_POS_FRAMES, middle)
    ret, frame = cap.read()
    cap.release()
    if not ret:
        raise ValueError("프레임을 읽을 수 없습니다.")
    frame = cv2.resize(frame, (128, 128))
    return frame.astype(np.float32) / 255.0

# 토크 및 모터
def calculate_torque(link_lengths):
    return np.mean(link_lengths) * 0.02

def determine_reduction_ratio(torque):
    return 10 if torque < 5 else 30 if torque < 10 else 50

def determine_load_condition(torque, reduction_ratio):
    return torque * reduction_ratio * 1.2

def recommend_motor(link_lengths):
    torque = calculate_torque(link_lengths)
    reduction_ratio = determine_reduction_ratio(torque)
    load = determine_load_condition(torque, reduction_ratio)
    if torque < 5:
        return torque, reduction_ratio, load, "소형 서보모터", "http://itempage3.auction.co.kr/DetailView.aspx?itemno=F205376245"
    elif torque < 10:
        return torque, reduction_ratio, load, "중형 서보모터", "https://smartstore.naver.com/satototal/products/11557842728"
    else:
        return torque, reduction_ratio, load, "대형 서보모터", "https://smartstore.naver.com/motorbank/products/5456441290"

# 예측 (전체 영상)
def predict_all_videos(robot_name):
    config = robot_models[robot_name]
    gt = config["gt"]
    videos = config["videos"]
    maes, mses, labels = [], [], []

    for i, video in enumerate(videos):
        fname = f"downloads/{video}"
        if not os.path.exists(fname):
            urllib.request.urlretrieve(base_url + video, fname)

        frame_paths = extract_frames(fname, f"temp_{robot_name}_{i}")
        x_test = np.stack([np.load(p) for p in frame_paths])
        y_test = np.tile(gt, (x_test.shape[0], 1))
        y_pred = model.predict(x_test)

        maes.append(np.mean(np.abs(y_test - y_pred)))
        mses.append(mean_squared_error(y_test, y_pred))
        labels.append(f"V{i+1}")

    # 그래프
    plt.figure(figsize=(10, 5))
    x = np.arange(len(labels))
    plt.bar(x - 0.15, maes, width=0.3, label="MAE")
    plt.bar(x + 0.15, mses, width=0.3, label="MSE")
    plt.xticks(x, labels)
    plt.title(f"{robot_name} 영상별 MAE/MSE")
    plt.ylabel("Error (mm / mm²)")
    plt.legend()
    plt.tight_layout()
    plot_path = f"plot_{robot_name}.png"
    plt.savefig(plot_path)
    plt.close()
    return "\n".join([f"{labels[i]}: MAE={maes[i]:.2f}, MSE={mses[i]:.2f}" for i in range(len(labels))]), plot_path

# 결과 링크 열기
def open_link(event):
    webbrowser.open(event.widget.cget("text"))

# 사용자 영상 예측
def run_single_prediction():
    path = path_entry.get()
    if not os.path.exists(path):
        messagebox.showerror("오류", "영상 파일이 존재하지 않습니다.")
        return
    try:
        frame = extract_middle_frame(path)
        x = np.expand_dims(frame, axis=0)
        pred = model.predict(x)[0]

        pred_label.config(text="\n".join([f"Link {i+1}: {l:.1f} mm" for i, l in enumerate(pred)]))
        torque, ratio, load, name, link = recommend_motor(pred)
        motor_label.config(text=f"토크: {torque:.2f} Nm | 감속비: {ratio}:1 | 부하: {load:.2f} Nm\n추천 모터: {name}")
        motor_link_label.config(text=link, fg="blue", cursor="hand2", font=("Arial", 10, "underline"))
        status_label.config(text="✅ 예측 완료", fg="green")
    except Exception as e:
        status_label.config(text=f"❌ 오류: {e}", fg="red")

# 전체 예측 실행
def run_batch_prediction():
    robot = robot_choice.get()
    result, img_path = predict_all_videos(robot)
    batch_result_label.config(text=result)
    batch_img = tk.PhotoImage(file=img_path)
    batch_img_label.configure(image=batch_img)
    batch_img_label.image = batch_img  # 이미지 유지

# 파일 선택
def select_file():
    file_path = filedialog.askopenfilename(filetypes=[("MP4 files", "*.mp4")])
    if file_path:
        path_entry.delete(0, tk.END)
        path_entry.insert(0, file_path)

# UI 구성
root = tk.Tk()
root.title("로봇팔 예측 & 모터 추천 통합 GUI")
root.geometry("700x700")

# 사용자 영상
tk.Label(root, text="🎞️ 사용자 영상 예측").pack()
frame = tk.Frame(root)
frame.pack(pady=5)
path_entry = tk.Entry(frame, width=50)
path_entry.pack(side=tk.LEFT)
tk.Button(frame, text="찾기", command=select_file).pack(side=tk.LEFT)
tk.Button(root, text="예측 실행", command=run_single_prediction, bg="blue", fg="white").pack(pady=5)
pred_label = tk.Label(root, text="", font=("Courier", 10), justify="left")
pred_label.pack()
motor_label = tk.Label(root, text="", font=("Arial", 10))
motor_label.pack()
motor_link_label = tk.Label(root, text="")
motor_link_label.pack()
motor_link_label.bind("<Button-1>", open_link)
status_label = tk.Label(root, text="대기 중...", fg="gray")
status_label.pack(pady=10)

# 구분선
ttk.Separator(root, orient="horizontal").pack(fill="x", pady=10)

# 전체 영상 예측
tk.Label(root, text="📊 학습 영상 성능 예측").pack()
robot_choice = ttk.Combobox(root, values=list(robot_models.keys()))
robot_choice.set("UR3e")
robot_choice.pack()
tk.Button(root, text="전체 영상 예측 실행", command=run_batch_prediction, bg="green", fg="white").pack(pady=5)
batch_result_label = tk.Label(root, text="", justify="left", font=("Courier", 9))
batch_result_label.pack()
batch_img_label = tk.Label(root)
batch_img_label.pack()

root.mainloop()